{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:22:07.014878Z",
     "start_time": "2021-03-26T02:22:06.547979Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from models import VBPR, ACF, CuratorNet\n",
    "from utils.data import extract_embedding\n",
    "from utils.metrics import (\n",
    "    auc_exact,\n",
    "    nDCG,\n",
    "    precision,\n",
    "    recall,\n",
    "    reciprocal_rank,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:22:08.555918Z",
     "start_time": "2021-03-26T02:22:08.553818Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET = \"Wikimedia\"\n",
    "\n",
    "# Model\n",
    "MODEL = \"ACF\"\n",
    "assert MODEL in [\"CuratorNet\", \"VBPR\", \"ACF\"]\n",
    "\n",
    "FEATURE_EXTRACTOR = \"resnet50\"\n",
    "assert FEATURE_EXTRACTOR in [\"alexnet\", \"vgg16\", \"resnet50\"]\n",
    "\n",
    "FEATURE_LAYER = \"layer4\"\n",
    "FEATURE_LAYER = FEATURE_LAYER if MODEL == \"ACF\" else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:22:10.377057Z",
     "start_time": "2021-03-26T02:22:10.375132Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mode\n",
    "# Use 'MODE_PROFILE = True' for CuratorNet-like training\n",
    "# Use 'MODE_PROFILE = False' for VBPR-like training\n",
    "MODE_PROFILE = MODEL in [\"CuratorNet\"]\n",
    "MODE_PROFILE = \"profile\" if MODE_PROFILE else \"user\"\n",
    "\n",
    "# Checkpoint (ex. 'VBPR_wikimedia')\n",
    "CHECKPOINT = f\"{MODEL}_wikimedia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:22:11.286344Z",
     "start_time": "2021-03-26T02:22:11.283714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Paths (general)\n",
    "CHECKPOINT_EXT = \"pt\" if MODEL == \"ACF\" else \"tar\" \n",
    "CHECKPOINT_PATH = os.path.join(\"checkpoints\", f\"{CHECKPOINT}.{CHECKPOINT_EXT}\")\n",
    "FEATURE_EXTRACTOR = f\"{FEATURE_EXTRACTOR}-{FEATURE_LAYER}\" if FEATURE_LAYER else FEATURE_EXTRACTOR\n",
    "EMBEDDING_PATH = os.path.join(\"data\", DATASET, f\"embedding-{FEATURE_EXTRACTOR}.npy\")\n",
    "EVALUATION_PATH = os.path.join(\"data\", DATASET, f\"naive-{MODE_PROFILE}-evaluation.csv\")\n",
    "\n",
    "# Paths (images)\n",
    "IMAGES_DIR = os.path.join(\"/\", \"mnt\", \"data2\", \"wikimedia\", \"mini-images-224-224-v2\")\n",
    "\n",
    "# General constants\n",
    "RNG_SEED = 0\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:22:12.084777Z",
     "start_time": "2021-03-26T02:22:12.082033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freezing RNG seed if needed\n",
    "if RNG_SEED is not None:\n",
    "    print(f\"\\nUsing random seed... ({RNG_SEED})\")\n",
    "    torch.manual_seed(RNG_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:22:13.288058Z",
     "start_time": "2021-03-26T02:22:12.722614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load embedding from file\n",
    "print(f\"\\nLoading embedding from file... ({EMBEDDING_PATH})\")\n",
    "embedding = np.load(EMBEDDING_PATH, allow_pickle=True)\n",
    "\n",
    "# Extract features and \"id2index\" mapping\n",
    "print(\"\\nExtracting data into variables...\")\n",
    "features, _, item_index2fn = extract_embedding(embedding, verbose=True)\n",
    "print(f\">> Features shape: {features.shape}\")\n",
    "del embedding  # Release some memory\n",
    "\n",
    "# Load evaluation dataframe\n",
    "print(\"\\nLoad evaluation dataframe\")\n",
    "evaluation_df = pd.read_csv(EVALUATION_PATH)\n",
    "# Transform lists from str to int\n",
    "string_to_list = lambda s: list(map(int, s.split()))\n",
    "evaluation_df[\"profile\"] = evaluation_df[\"profile\"].apply(\n",
    "    lambda s: string_to_list(s) if isinstance(s, str) else s,\n",
    ")\n",
    "evaluation_df[\"predict\"] = evaluation_df[\"predict\"].apply(\n",
    "    lambda s: string_to_list(s) if isinstance(s, str) else s,\n",
    ")\n",
    "# Group evaluations by profile and user\n",
    "evaluation_df[\"profile\"] = evaluation_df[\"profile\"].map(tuple)\n",
    "evaluation_df = evaluation_df.groupby([\"profile\", \"user_id\"]).agg({\"predict\": sum}).reset_index()\n",
    "evaluation_df[\"profile\"] = evaluation_df[\"profile\"].map(list)\n",
    "print(f\">> Evaluation: {evaluation_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:25:06.857895Z",
     "start_time": "2021-03-26T02:25:04.884129Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create device instance\n",
    "print(\"\\nDevice initialization\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and USE_GPU else \"cpu\")\n",
    "if torch.cuda.is_available() != USE_GPU:\n",
    "    print((f\"\\nNotice: Not using GPU - \"\n",
    "           f\"Cuda available ({torch.cuda.is_available()}) \"\n",
    "           f\"does not match USE_GPU ({USE_GPU})\"\n",
    "    ))\n",
    "\n",
    "# Loading checkpoint\n",
    "if CHECKPOINT is not None:\n",
    "    print(\"\\nLoading checkpoint\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=torch.device(\"cpu\"))\n",
    "    if 'epoch' in checkpoint and 'accuracy' in checkpoint:\n",
    "        print(f\">> Best epoch: {checkpoint['epoch']} | Best accuracy: {checkpoint['accuracy']}\")\n",
    "    elif 'epoch' in checkpoint and 'loss' in checkpoint:\n",
    "        print(f\">> Best epoch: {checkpoint['epoch']} | Best Loss: {checkpoint['loss']}\")\n",
    "\n",
    "# Model initialization\n",
    "print(\"\\nModel initialization\")\n",
    "model = ACF.from_checkpoint(checkpoint, device=device)\n",
    "    \n",
    "# Change model mode to eval\n",
    "print(\"\\nChanging model mode to eval\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:25:12.155616Z",
     "start_time": "2021-03-26T02:25:12.153969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict all\n",
    "# If True, ranks every item including already consumed items\n",
    "# If False, ranks ALL - PROFILE (consumed) + PREDICT (ground truth)\n",
    "PREDICT_ALL = False\n",
    "N_ITEMS = len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_std_size = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:25:54.837633Z",
     "start_time": "2021-03-26T02:25:54.834283Z"
    }
   },
   "outputs": [],
   "source": [
    "ROW = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:25:55.556066Z",
     "start_time": "2021-03-26T02:25:55.538691Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Row in evaluation dataframe\n",
    "row = evaluation_df.iloc[ROW]\n",
    "\n",
    "# Load data into tensors\n",
    "profile = torch.tensor(row.profile).to(device, non_blocking=True).unsqueeze(0)\n",
    "user_id = torch.tensor([int(row.user_id)]).to(device, non_blocking=True)\n",
    "predict = torch.tensor(row.predict).to(device, non_blocking=True)\n",
    "\n",
    "# Prediction\n",
    "acf_profile = profile + 1\n",
    "scores, *attns = model.recommend_all(user_id, acf_profile, return_attentions=True)\n",
    "component_attns, profile_attns = attns\n",
    "\n",
    "# Ranking\n",
    "pos_of_evals = (torch.argsort(scores, descending=True)[..., None] == predict).any(-1).nonzero().flatten()\n",
    "if not PREDICT_ALL:\n",
    "    pos_of_profi = (torch.argsort(scores, descending=True)[..., None] == profile).any(-1).nonzero().flatten()\n",
    "    pos_of_evals -= (pos_of_profi < pos_of_evals).sum()\n",
    "\n",
    "# Display metrics\n",
    "print(f\"| {'-' * 15} | {'-' * 7} |\")\n",
    "print(f\"| {'Metric':^15} | {'Score':^7} |\")\n",
    "print(f\"| {'-' * 15} | {'-' * 7} |\")\n",
    "print(f\"| {'AUC':^15} | {auc_exact(pos_of_evals, N_ITEMS):.5f} |\")\n",
    "print(f\"| {'RR':^15} | {reciprocal_rank(pos_of_evals):.5f} |\")\n",
    "for k in [20, 100, 500]:\n",
    "    print(f\"| {'-' * 15} | {'-' * 7} |\")\n",
    "    print(f\"| {f'Recall@{k}':^15} | {recall(pos_of_evals, k):.5f} |\")\n",
    "    print(f\"| {f'Precision@{k}':^15} | {precision(pos_of_evals, k):.5f} |\")\n",
    "    print(f\"| {f'nDCG@{k}':^15} | {nDCG(pos_of_evals, k):.5f} |\")\n",
    "print(f\"| {'-' * 15} | {'-' * 7} |\")\n",
    "\n",
    "# Profile and prediction\n",
    "profile = profile.cpu().numpy().flatten()\n",
    "predict = predict.cpu().numpy().flatten()\n",
    "# Ranking\n",
    "K = 20\n",
    "ranking = torch.argsort(scores, descending=True).cpu().numpy().flatten()\n",
    "if not PREDICT_ALL:\n",
    "    ranking = ranking[(~np.isin(ranking, profile)) | (np.isin(ranking, predict))]\n",
    "ranking = ranking[:K]\n",
    "print()\n",
    "print(f\"Size of profile: {profile.size}\")\n",
    "print(f\"Position of actual items: {pos_of_evals.cpu().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_attentions, profile_attentions = attns\n",
    "component_attentions = component_attentions.squeeze()\n",
    "profile_attn_dict = dict(zip(profile.tolist(), profile_attentions.squeeze().T.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_attentions, profile_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T02:26:02.034249Z",
     "start_time": "2021-03-26T02:26:00.729988Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "COLUMNS = 10\n",
    "ELEMENTS = {\n",
    "    \"Consumed\": profile,\n",
    "    \"Recommendation\": ranking,\n",
    "    \"Ground truth\": predict,\n",
    "}\n",
    "SHOW_FILENAME = False\n",
    "\n",
    "for label, items in ELEMENTS.items():\n",
    "    n_rows = ((len(items) - 1) // COLUMNS + 1)\n",
    "    fig = plt.figure(figsize=(COLUMNS * 2, 3 * n_rows))\n",
    "    plt.title(f\"{label.title()} (n={len(items)})\", fontdict={'fontweight': 'bold'})\n",
    "    plt.axis(\"off\")\n",
    "    for i, img_id in enumerate(items, start=1):\n",
    "        img_fn = item_index2fn[img_id]\n",
    "        image = Image.open(os.path.join(IMAGES_DIR, img_fn))\n",
    "        image = to_std_size(image)\n",
    "        ax = fig.add_subplot(n_rows, COLUMNS, i)\n",
    "        if SHOW_FILENAME:\n",
    "            ax.set_title(img_fn)\n",
    "        if label == \"Consumed\":\n",
    "            attention_score = profile_attn_dict[img_id] if isinstance(profile_attn_dict[img_id], float) else profile_attn_dict[img_id][0] # TODO: MHAttn\n",
    "            ax.set_title(f\"attn={attention_score:.5f}\", color=\"red\")\n",
    "        elif label == \"Recommendation\":\n",
    "            if img_id in predict:\n",
    "                ax.patch.set_edgecolor(\"green\")\n",
    "                ax.patch.set_linewidth(\"5\")\n",
    "                if SHOW_FILENAME:\n",
    "                    ax.set_title(img_fn, color=\"green\")\n",
    "                else:\n",
    "                    ax.set_title(\"Ground truth\", color=\"green\")\n",
    "            elif img_id in profile:\n",
    "                ax.patch.set_edgecolor(\"red\")\n",
    "                ax.patch.set_linewidth(\"5\")\n",
    "                if SHOW_FILENAME:\n",
    "                    ax.set_title(img_fn, color=\"red\")\n",
    "                else:\n",
    "                    ax.set_title(\"Consumed\", color=\"red\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transparent_cmap(cmap):\n",
    "    \"Copy colormap and set alpha values\"\n",
    "\n",
    "    mycmap = cmap\n",
    "    mycmap._init()\n",
    "    mycmap._lut[:,-1] = 0.5\n",
    "    return mycmap\n",
    "\n",
    "\n",
    "pink_cmap = ListedColormap(['#f7f4f9','#e7e1ef','#d4b9da','#c994c7','#df65b0','#e7298a','#ce1256','#91003f'])\n",
    "blue_cmap = ListedColormap(['#f7fbff', '#deebf7', '#c6dbef', '#9ecae1', '#6baed6', '#4292c6', '#2171b5', '#084594'])\n",
    "purple_cmap = ListedColormap(['#fcfbfd','#efedf5','#dadaeb','#bcbddc','#9e9ac8','#807dba','#6a51a3','#4a1486'])\n",
    "\n",
    "cmaps = [pink_cmap, blue_cmap, purple_cmap, plt.cm.gist_gray]\n",
    "cmaps = [transparent_cmap(cmap) for cmap in cmaps]\n",
    "\n",
    "n_rows = len(cmaps)\n",
    "fig = plt.figure(figsize=(8, 1.2 * n_rows))\n",
    "plt.title(\"Attention Colormaps\", fontdict={'fontweight': 'bold'})\n",
    "plt.axis(\"off\")\n",
    "for i, cmap in enumerate(cmaps):\n",
    "    ax = fig.add_axes([0.05, 0.75 - (0.75 / n_rows) * i, 0.9, 0.3/n_rows])\n",
    "    cb = mpl.colorbar.ColorbarBase(ax, cmap=cmap, orientation='horizontal')\n",
    "    cb.set_label(f'colormap={i}')\n",
    "    cb.set_ticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_idx = 0\n",
    "cmap_idx = 0\n",
    "\n",
    "img_id = profile[profile_idx]\n",
    "img_fn = item_index2fn[img_id]\n",
    "image = Image.open(os.path.join(IMAGES_DIR, img_fn))\n",
    "image = to_std_size(image)\n",
    "\n",
    "image_attn = component_attentions[profile_idx]\n",
    "image_attn = image_attn.reshape((7,7)).detach().cpu().numpy()\n",
    "image_attn = Image.fromarray(image_attn)\n",
    "image_attn = image_attn.resize((224,224))\n",
    "image_attn = np.array(image_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_columns, n_rows = 2, 1\n",
    "fig = plt.figure(figsize=(n_columns * 4, 3 * n_rows))\n",
    "\n",
    "plt.title(f\"Component Attention\", fontdict={'fontweight': 'bold'})\n",
    "plt.axis(\"off\")\n",
    "\n",
    "img_ax = fig.add_subplot(n_rows, n_columns, 1)\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "img_ax.imshow(image)\n",
    "    \n",
    "attn_ax = fig.add_subplot(n_rows, n_columns, 2)\n",
    "\n",
    "y, x = np.mgrid[0:224, 0:224]\n",
    "cmap = cmaps[cmap_idx]\n",
    "cb = attn_ax.contourf(x, y, image_attn, 10, cmap=cmap, antialiased=True)\n",
    "plt.colorbar(cb)\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "attn_ax.imshow(image)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
